{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "print('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo():\n",
    "    print('foo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foo\n"
     ]
    }
   ],
   "source": [
    "foo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "#pandas.read_excel(r'C:\\Users\\n1555085\\Downloads\\Copy of CSAT Help hub April Responses.xlsx')\n",
    "sheet = pandas.read_excel(r'C:\\Users\\n1555085\\Downloads\\May Help Hub Data.xlsx')\n",
    "courtesy = sheet['Unnamed: 9'].dropna().values.tolist()[1:]\n",
    "effectiveness = sheet['Unnamed: 10'].dropna().values.tolist()[1:]\n",
    "timeliness = sheet['Unnamed: 11'].dropna().values.tolist()[1:]\n",
    "understanding = sheet['Unnamed: 12'].dropna().values.tolist()[1:]\n",
    "nps = sheet['Unnamed: 13'].dropna().values.tolist()[1:]\n",
    "comments = courtesy + effectiveness + timeliness + understanding + nps\n",
    "date = sheet['Unnamed: 1'].dropna().values.tolist()[1:]\n",
    "#should add completion rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of courtesy comments: 10\n",
      "# of effectiveness comments: 17\n",
      "# of timeliness comments: 24\n",
      "# of understanding comments: 13\n",
      "# of nps comments: 148\n",
      "# of comments: 212\n"
     ]
    }
   ],
   "source": [
    "print(f'# of courtesy comments: {len(courtesy)}')\n",
    "print(f'# of effectiveness comments: {len(effectiveness)}')\n",
    "print(f'# of timeliness comments: {len(timeliness)}')\n",
    "print(f'# of understanding comments: {len(understanding)}')\n",
    "print(f'# of nps comments: {len(nps)}')\n",
    "print(f'# of comments: {len(comments)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1954 888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Spenser Cameron set assisted IT issues. He exceptional trying assist newcomer new systems.',\n",
       " 'second consultant awesome appropriate follow well letting know break fix consultants suggestion since I could not receive emails. She best.',\n",
       " 'support personnel helpful patient issue I',\n",
       " 'fast service.',\n",
       " 'Greeting robotic, however loosened conversation went on.']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read from corpus, remove stopwords\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "with open(r'C:\\Users\\n1555085\\Downloads\\Project\\positiveComments.txt', 'r') as f:\n",
    "    posReviews = f.readlines()\n",
    "with open(r'C:\\Users\\n1555085\\Downloads\\Project\\negativeComments.txt', 'r') as f:\n",
    "    negReviews = f.readlines()\n",
    "print(len(posReviews), len(negReviews))\n",
    "\n",
    "sw = set(stopwords.words('english') + list(punctuation))\n",
    "notStopwords = ['not', 'no', '!', 'but', 'too', 'have', 'had']\n",
    "\n",
    "def removeStopwords(review):\n",
    "    return ' '.join([word for word in review.split() if word not in sw or word in notStopwords])\n",
    "posReviews = list(filter(lambda s: s , list(map(removeStopwords, posReviews))))\n",
    "negReviews = list(filter(lambda s: s , list(map(removeStopwords, negReviews))))\n",
    "\n",
    "posReviews[0:5]\n",
    "#negReviews[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define pos and neg bag-of words, and vocabulary\n",
    "\n",
    "posWords = [word.lower() for review in posReviews for word in review.split()]\n",
    "negWords = [word.lower() for review in negReviews for word in review.split()]\n",
    "vocabulary = list(set(posWords + negWords))\n",
    "#vocabulary[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define training data: list of (review list of words, label) tuples\n",
    "trainingData = [(r.split(), 'pos') for r in posReviews] + [(r.split(), 'neg') for r in negReviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NAIVE BAYES CLASSIFIER: extract feature vector from each review, train classifier\n",
    "def featureVector(review):\n",
    "    reviewWords = set(review)\n",
    "    features = {}\n",
    "    for word in vocabulary:\n",
    "        features[word] = word in reviewWords\n",
    "    return features\n",
    "\n",
    "naiveBayesClassifier = nltk.NaiveBayesClassifier.train(nltk.classify.apply_features(featureVector, trainingData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classify functions\n",
    "def NBclassify(review):\n",
    "    review = removeStopwords(review)\n",
    "    features = featureVector(review.split())\n",
    "    probDist = naiveBayesClassifier.prob_classify(features)\n",
    "    confidence = max(probDist.prob('pos'), probDist.prob('neg'))\n",
    "    #pos and neg add to 1\n",
    "    return (naiveBayesClassifier.classify(features).upper(), confidence)\n",
    "\n",
    "def NBclassifyComments(comments):\n",
    "    return [(c, NBclassify(c)) for c in comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1st ticket they marked resolved even though it was not.',\n",
       "  ('POS', 0.9366672276167465)),\n",
       " ('no next steps. have to restart my request from scratch.',\n",
       "  ('POS', 0.618661262748057)),\n",
       " ('See previous comment.', ('POS', 0.9999648658586715)),\n",
       " ('No response nor assistance was given', ('POS', 0.9996889424613481)),\n",
       " ('I was given a solution that did not meet my needs. Finally I was directed to a JIRA site for another team and my ticket was resolved although my issue still remains. Hopefully the JIRA team can help.',\n",
       "  ('NEG', 0.9967503117422805)),\n",
       " ('there is a fix without calling internet which i was told to do',\n",
       "  ('POS', 0.9878065638447872)),\n",
       " ('.', ('POS', 0.9998960483520787)),\n",
       " ('I was asked multiple times to keep doing the same thing by different people. Clear my cache and cookies when I literally had just done that 1 minute prior. That was a bit frustrating.',\n",
       "  ('NEG', 0.9999167705781233)),\n",
       " ('Unfortunately recreating my VDE is not an ideal scenario. Having said that, it has nothing to do with the person that picked up this ticket.',\n",
       "  ('NEG', 0.9817364130652106)),\n",
       " ('there was a large gap from it being escalated to when it was resolved',\n",
       "  ('POS', 0.9998606801312869)),\n",
       " ('n/a as issue was resolved without HD assist', ('POS', 0.9996733586005394)),\n",
       " ('The issue is not resolved, not to the fault of the IT team.',\n",
       "  ('POS', 0.9937227321236074)),\n",
       " ('Contacting myself is not a good solution and I dont understand why myself as a current member of a shared inbox would need my direct reports permission to share access with another employee.',\n",
       "  ('NEG', 0.9775308708803119)),\n",
       " ('Last contact with your rep indicated that this issue was being reviewed by others for resolution. However, I then got an email telling me my ticket has been closed as resolved. I do know that we are pursuing this issue with other sources, but that should have been communicated to me, rather than me having to find out by going to my manager and others to discuss next steps.',\n",
       "  ('NEG', 0.9999999755628214)),\n",
       " ('satisfied with the service', ('POS', 0.9999751412960836)),\n",
       " ('Nothing of significance has been reported as to what the next steps should be. I received a note that I might have to re-order and re-enter all of the information for the report, which is something that has never had to be done in the past.',\n",
       "  ('NEG', 0.9995954804110756)),\n",
       " ('very helpfull, understanding, and friendly in helping me with my issues',\n",
       "  ('POS', 0.9999934737858833))]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeledComments = NBclassifyComments(effectiveness)\n",
    "labeledComments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('english'))\n",
    "# note, might want to remove following stopwords: ['not', 'no', '!', 'but', 'too', 'have', 'had']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
