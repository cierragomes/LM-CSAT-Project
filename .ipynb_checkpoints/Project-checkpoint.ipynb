{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "print('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foo\n"
     ]
    }
   ],
   "source": [
    "def foo():\n",
    "    print('foo')\n",
    "foo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of courtesy comments: 10\n",
      "# of effectiveness comments: 17\n",
      "# of timeliness comments: 24\n",
      "# of understanding comments: 13\n",
      "# of nps comments: 148\n",
      "# of comments: 212\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "#pandas.read_excel(r'C:\\Users\\n1555085\\Downloads\\Copy of CSAT Help hub April Responses.xlsx')\n",
    "sheet = pandas.read_excel(r'C:\\Users\\n1555085\\Downloads\\May Help Hub Data.xlsx')\n",
    "courtesy = sheet['Unnamed: 9'].dropna().values.tolist()[1:]\n",
    "effectiveness = sheet['Unnamed: 10'].dropna().values.tolist()[1:]\n",
    "timeliness = sheet['Unnamed: 11'].dropna().values.tolist()[1:]\n",
    "understanding = sheet['Unnamed: 12'].dropna().values.tolist()[1:]\n",
    "nps = sheet['Unnamed: 13'].dropna().values.tolist()[1:]\n",
    "comments = courtesy + effectiveness + timeliness + understanding + nps\n",
    "date = sheet['Unnamed: 1'].dropna().values.tolist()[1:]\n",
    "#should add completion rate\n",
    "\n",
    "print(f'# of courtesy comments: {len(courtesy)}')\n",
    "print(f'# of effectiveness comments: {len(effectiveness)}')\n",
    "print(f'# of timeliness comments: {len(timeliness)}')\n",
    "print(f'# of understanding comments: {len(understanding)}')\n",
    "print(f'# of nps comments: {len(nps)}')\n",
    "print(f'# of comments: {len(comments)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4553 1574\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Spenser Cameron set assisted issues. exceptional trying assist newcomer new systems.',\n",
       " 'second consultant awesome appropriate follow well letting know break fix consultants suggestion since could not receive emails. best.',\n",
       " 'support personnel helpful patient issue',\n",
       " 'fast service.',\n",
       " 'Greeting robotic, however loosened conversation went on.']"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read from corpus, remove stopwords\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "with open(r'C:\\Users\\n1555085\\Downloads\\Project\\positiveComments.txt', 'r') as f:\n",
    "    posReviews = f.readlines()\n",
    "with open(r'C:\\Users\\n1555085\\Downloads\\Project\\negativeComments.txt', 'r') as f:\n",
    "    negReviews = f.readlines()\n",
    "print(len(posReviews), len(negReviews))\n",
    "\n",
    "sw = set(stopwords.words('english') + list(punctuation))\n",
    "notStopwords = ['not', 'no', '!', 'but', 'too', 'have', 'had']\n",
    "\n",
    "def removeStopwords(review):\n",
    "    #review.translate(None, string.punctuation)\n",
    "    return ' '.join([word for word in review.split() if word.lower() not in sw or word.lower() in notStopwords])\n",
    "posReviews = list(filter(lambda s: s , list(map(removeStopwords, posReviews))))\n",
    "negReviews = list(filter(lambda s: s , list(map(removeStopwords, negReviews))))\n",
    "\n",
    "posReviews[0:5]\n",
    "#negReviews[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define pos and neg bag-of words, and vocabulary\n",
    "\n",
    "posWords = [word.lower() for review in posReviews for word in review.split()]\n",
    "negWords = [word.lower() for review in negReviews for word in review.split()]\n",
    "vocabulary = list(set(posWords + negWords))\n",
    "#vocabulary[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define training data: list of (review list of words, label) tuples\n",
    "trainingData = [(r.split(), 'pos') for r in posReviews] + [(r.split(), 'neg') for r in negReviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NAIVE BAYES CLASSIFIER: extract feature vector from each review, train classifier\n",
    "def featureVector(reviewSplit):\n",
    "    reviewWords = set(reviewSplit)\n",
    "    features = {}\n",
    "    for word in vocabulary:\n",
    "        features[word] = word in reviewWords\n",
    "    return features\n",
    "\n",
    "naiveBayesClassifier = nltk.NaiveBayesClassifier.train(nltk.classify.apply_features(featureVector, trainingData))\n",
    "\n",
    "#classify functions\n",
    "def NBclassify(review):\n",
    "    review = removeStopwords(review)\n",
    "    features = featureVector(review.split())\n",
    "    probDist = naiveBayesClassifier.prob_classify(features)\n",
    "    confidence = max(probDist.prob('pos'), probDist.prob('neg'))\n",
    "    #pos and neg add to 1\n",
    "    return (naiveBayesClassifier.classify(features).upper(), confidence)\n",
    "\n",
    "def NBclassifyComments(comments):\n",
    "    return [(c, NBclassify(c)) for c in comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBlabeledComments = NBclassifyComments(effectiveness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM Classifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#vectorizer = TfidfVectorizer(min_df = 5, max_df = 0.8, sublinear_tf = True, use_idf = True, ngram_range=(1, 2))\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2), token_pattern=r'\\b\\w+\\b', min_df=1)\n",
    "train_vectors = vectorizer.fit_transform(posReviews + negReviews)\n",
    "labelsList = ['pos'] * len(posReviews) + ['neg'] * len(negReviews)\n",
    "\n",
    "classifier_linear = SVC(kernel='linear', probability = True)\n",
    "classifier_linear.fit(train_vectors, labelsList)\n",
    "\n",
    "classifier_poly = SVC(kernel='poly', probability = True)\n",
    "classifier_poly.fit(train_vectors, labelsList)\n",
    "\n",
    "classifier_rbf = SVC(kernel='rbf', probability = True)\n",
    "classifier_rbf.fit(train_vectors, labelsList)\n",
    "\n",
    "classifier_sigmoid = SVC(kernel='sigmoid', probability = True)\n",
    "classifier_sigmoid.fit(train_vectors, labelsList)\n",
    "\n",
    "# svm kernel can be ‘linear’, ‘poly’, ‘rbf’, or ‘sigmoid’\n",
    "def SVMclassify(review, kernel):\n",
    "    review = removeStopwords(review)\n",
    "    review_vector = vectorizer.transform([review]) # vectorizing\n",
    "    if kernel == 'linear':\n",
    "        return (classifier_linear.predict(review_vector)[0], max(classifier_rbf.predict_proba(review_vector)[0]))\n",
    "    elif kernel == 'poly':\n",
    "        return (classifier_poly.predict(review_vector)[0], max(classifier_rbf.predict_proba(review_vector)[0]))\n",
    "    elif kernel == 'rbf':\n",
    "        return (classifier_rbf.predict(review_vector)[0], max(classifier_rbf.predict_proba(review_vector)[0]))\n",
    "    elif kernel == 'sigmoid':\n",
    "        return (classifier_sigmoid.predict(review_vector)[0], max(classifier_rbf.predict_proba(review_vector)[0]))\n",
    "    return None\n",
    "\n",
    "def SVMclassifyComments(comments, kernel):\n",
    "    return [(c, SVMclassify(c, kernel)) for c in comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Labelling new data\n",
    "SVMlabelledComments = SVMclassifyComments(comments, 'rbf')\n",
    "labelledPos = []\n",
    "labelledNeg = []\n",
    "#lc is (<comment>, (<pos/neg>, <confidence>))\n",
    "for lc in SVMlabelledComments:\n",
    "    if lc[1][0] == 'pos':\n",
    "        labelledPos.append(lc[0])\n",
    "    elif lc[1][0] == 'neg':\n",
    "        labelledNeg.append(lc[0])\n",
    "#remove stopwords\n",
    "labelledPos = list(filter(lambda s: s , list(map(removeStopwords, labelledPos))))\n",
    "labelledNeg = list(filter(lambda s: s , list(map(removeStopwords, labelledNeg))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 1:  [('issue', 1.41), ('resolved', 0.99), ('solved', 0.45), ('great', 0.4), ('service', 0.36), ('problem', 0.3), ('timely', 0.24), ('contacted', 0.24), ('quickly', 0.24), ('completely', 0.24), ('support', 0.2), ('fix', 0.19), ('friendly', 0.17), ('polite', 0.17), ('time', 0.17), ('help', 0.17), ('without', 0.17), ('courteous', 0.16), ('helpful', 0.16), ('first', 0.16), ('resolve', 0.15), ('it', 0.15), ('ticket', 0.14), ('work', 0.14), ('job', 0.14), ('late', 0.13), ('professional', 0.13), ('speed', 0.13), ('able', 0.13), ('addressed', 0.12), ('actually', 0.12), ('employees', 0.12), ('took', 0.11), ('needed', 0.11), ('request', 0.11), ('had', 0.11), ('but', 0.11), ('right', 0.11), ('kind', 0.11), ('understood', 0.11), ('worked', 0.1), ('understand', 0.1), ('away', 0.1), ('hub', 0.1), ('assist', 0.1), ('reached', 0.09), ('hd', 0.09), ('delay', 0.09), ('call', 0.09), ('manner', 0.09)]\n",
      "\n",
      "Topic 2:  [('quick', 1.54), ('response', 1.09), ('efficient', 0.99), ('resolution', 0.87), ('solution', 0.28), ('easy', 0.19), ('clear', 0.19), ('follow', 0.18), ('help', 0.18), ('fix', 0.18), ('rapid', 0.17), ('expertise', 0.16), ('fixed', 0.13), ('via', 0.13), ('etc', 0.13), ('thanks', 0.11), ('assistance', 0.11), ('would', 0.1), ('friendly', 0.1), ('swift', 0.1), ('pleasant', 0.09), ('email', 0.09), ('had', 0.08), ('quicker', 0.08), ('proactive', 0.07), ('canned', 0.07), ('min', 0.07), ('nice', 0.07), ('exactly', 0.07), ('teams', 0.07), ('call', 0.06), ('fast', 0.06), ('handled', 0.06), ('one', 0.06), ('issues', 0.06), ('knew', 0.06), ('contact', 0.06), ('ms', 0.06), ('but', 0.06), ('immediate', 0.05), ('question', 0.05), ('turn', 0.05), ('provided', 0.04), ('30', 0.04), ('took', 0.04), ('within', 0.04), ('around', 0.04), ('fit', 0.04), ('purpose', 0.04), ('im', 0.04)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "def get_topics(components, feature_names, n=50):\n",
    "    for idx, topic in enumerate(components):\n",
    "        print(\"\\nTopic %d: \" % (idx+1), [(feature_names[i], topic[i].round(2)) for i in topic.argsort()[:-n - 1:-1]])\n",
    "        \n",
    "v = TfidfVectorizer(max_features=1000) \n",
    "X = v.fit_transform(labelledPos)\n",
    "\n",
    "nmf_model = NMF(n_components=2, init='random', random_state=0)\n",
    "nmf_top = nmf_model.fit_transform(X)\n",
    "\n",
    "terms = v.get_feature_names() \n",
    "get_topics(nmf_model.components_,terms)\n",
    "nmf_model.components_\n",
    "\n",
    "for idx, topic in enumerate(nmf_model.components_):\n",
    "    if idx == 0:\n",
    "        topic_x = [(terms[i], topic[i].round(2)) for i in topic.argsort()[:-1000 - 1:-1]]\n",
    "        topic_x = {i[0]:i[1] for i in topic_x}\n",
    "#wordcloud = WordCloud(width = 3000, height = 3000, stopwords=STOPWORDS, background_color=\"white\", min_font_size = 30)\n",
    "#wordcloud = wordcloud.generate_from_frequencies(topic_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wordcloud stuff\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cloudStopwords = set(stopwords.words('english') + list(punctuation) + ['resolve', 'resolved', 'resolution', 'issue', 'problem', 'solve'])\n",
    "\n",
    "#calculates word frequencies for generating wordcloud\n",
    "#parameter should be list of comments, returns dictionary\n",
    "def wordFrequencies(commentList):\n",
    "    dictionary = {}\n",
    "    words = ' '.join(commentList).lower().split()\n",
    "    for w in words:\n",
    "        if w not in dictionary and w not in cloudStopwords:\n",
    "            dictionary[w] = words.count(w)\n",
    "    return dictionary\n",
    "\n",
    "def customWordFrequencies(commentList, customWords):\n",
    "    dictionary = {}\n",
    "    words = ' '.join(commentList).lower().split()\n",
    "    for w in words:\n",
    "        if w in customWords and w not in cloudStopwords:\n",
    "            dictionary[w] = words.count(w)\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADnCAYAAAC9roUQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAADKUlEQVR4nO3UMQEAIAzAMMC/5+GiHCQKenXPzAKgcV4HAPzEdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIHQBcjcEy3+fc28AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "posCloud = WordCloud(width = 2000, height = 2000, background_color=\"white\", min_font_size = 30)\n",
    "posCloud.generate_from_frequencies(wordFrequencies(labelledPos))\n",
    "\n",
    "negCloud = WordCloud(width = 2000, height = 2000, background_color=\"white\", min_font_size = 30)\n",
    "negCloud.generate_from_frequencies(wordFrequencies(labelledNeg))\n",
    "\n",
    "#posCloud.to_file(\"positive_comments_wc.png\")\n",
    "#negCloud.to_file(\"negative_comments_wc.png\")\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.figure(figsize=(30, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clustering Stuff\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from collections import defaultdict\n",
    "from heapq import nlargest\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df = 5, max_df = 0.8, sublinear_tf = True, use_idf = True, ngram_range=(1, 2))\n",
    "\n",
    "#uses KMeans algorithm to cluster comments into 3 numClusters\n",
    "#takes in comment list and number of clusters as param\n",
    "#returns dictionary of clusters (cluster number key : list of comments value)\n",
    "def clusterComments(comments, numClusters):\n",
    "    x = tfidf.fit_transform(comments)\n",
    "    km = KMeans(n_clusters = numClusters, init = 'k-means++', max_iter = 100, n_init = 1, verbose = True)\n",
    "    km.fit(x)\n",
    "    np.unique(km.labels_, return_counts = True)\n",
    "    dictionary = {}\n",
    "    for i,cluster in enumerate(km.labels_):\n",
    "        c = comments[i]\n",
    "        if cluster not in dictionary.keys():\n",
    "            dictionary[cluster] = c\n",
    "        else:\n",
    "            dictionary[cluster] += c\n",
    "    return dictionary\n",
    "\n",
    "#takes in result of clusterComments\n",
    "#returns dictionary of <cluster : keywords>\n",
    "def findKeywords(dictionary):\n",
    "    keywords = {}\n",
    "    for cluster in range(len(dictionary)):\n",
    "        word_sent = word_tokenize(text[cluster].lower())\n",
    "        freq = FreqDist(word_sent)\n",
    "        keywords[cluster] = nlargest(100, freq, key=freq.get)\n",
    "    return keywords\n",
    "\n",
    "#takes in result of clusterComments\n",
    "#returns dictionary of <cluster : keywords>\n",
    "def findUniqueKeywords(dictionary):\n",
    "    uniqueKeywords = {}\n",
    "    keywords = findKeywords(dictionary)\n",
    "    for cluster in range(len(dictionary)):\n",
    "        other_clusters = list(set(range(len(dictionary))) - set([cluster]))\n",
    "        keywords_other_clusters = set([])\n",
    "        for i in range(len(other_clusters)):\n",
    "            keywords_other_clusters = keywords_other_clusters.union(set(keywords[other_clusters[i]]))\n",
    "        unique = set(keywords[cluster]) - keywords_other_clusters\n",
    "        uniqueKeywords[cluster] = nlargest(100, unique, key=counts[cluster].get)\n",
    "    return uniqueKeywords\n",
    "\n",
    "#keywords is dictionary<int : [str]>\n",
    "#uniqueKeys is dictionary<int : [str]>\n",
    "#counts is dictionary<int : FreqDist>\n",
    "\n",
    "#takes in a dictionary of <cluster : keywords> as argument\n",
    "#returns nothing, just generates wordclouds for each cluster\n",
    "def generateClusterClouds(comments, numClusters):\n",
    "    clusterCommentsDictionary = clusterComments(comments, numClusters)\n",
    "    clusterKeywordDictionary = findKeywords(clusterCommentsDictionary)\n",
    "    for cluster in clusterKeywordDictionary:\n",
    "        customCloud = WordCloud(width = 2000, height = 2000, background_color=\"white\", min_font_size = 30)\n",
    "        \n",
    "        commentsOfCluster = clusterCommentsDictionary[cluster]\n",
    "        #print(commentsOfCluster)\n",
    "        customWords = clusterKeywordDictionary[cluster]\n",
    "        print(customWords)\n",
    "        \n",
    "        frequencies = customWordFrequencies(commentsOfCluster, customWords)\n",
    "        print(frequencies)\n",
    "        \n",
    "        customCloud.generate_from_frequencies(frequencies)\n",
    "        plt.imshow(customCloud, interpolation=\"bilinear\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration 0, inertia 275.2452316980838\n",
      "Iteration 1, inertia 133.07424267964342\n",
      "Iteration 2, inertia 132.55557664109077\n",
      "Iteration 3, inertia 132.43409669942707\n",
      "Converged at iteration 3: strict convergence.\n",
      "['resolution', ',', 'response', '.', 'via', 'quick', 'efficient', '!', 'email', 'teams', 'would', 'access', 'thanks', 'issue', 'canned', 'response.would', 'great', 'quickerhd', 'reached', 'im', 'meetings', 'seems', 'inefficient', 'check', 'status', 'let', 'know', 'available.quick', 'clear.quick', 'turn', 'around', 'knew', 'exactlyfaster', 'simple', 'requests', 'week', 'wait', 'basic', 'required', 'system', 'role', 'unacceptable', 'intentional', 'action', 'group', 'processes', 'request.quick', 'helpquicker', 'bestquick', 'resolutionquick', 'proactive', 'nicequick', 'followquick', 'fix', 'response/resolutionquick', 'efficientquick', 'expertisequick', 'regarding', 'appraisal', 'well', 'answer', 'additional', 'question', 'hadcontact', 'quickly', 'ms', 'message', 'excellent', 'communication', 'expectations.quick', 'friendly', 'assistancequick', '2', 'issues', 'handled', 'one', 'call', 'immediate', 'within', '30', 'minincredible', 'swift', 'coupled', 'sherri', 'snowâ€™s', 'follow', 'clear', 'explanation', 'made', 'among', 'pleasant', 'experiences', 'iâ€™ve', 'had', 'interacting', 'it', 'solution', 'etcquick', 'resolutionresolution', 'took']\n",
      "{'2': 3}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['issue', ',', '.', 'resolved', '!', 'quickly', 'timely', 'resolve', 'without', 'hub', 'but', 'job', 'worked', 'lm', 'work', 'manner', 'result', 'solution', 'help', 'step', 'care', 'ticket', 'submitted', 'professional', 'it', 'mohammed', 'large', 'gap', 'escalated', 'resolvedn/a', 'hd', 'assistcreated', 'tech', 'request', '4/30', '5/25.contacted', 'late', 'resolved.rep', 'reached', 'via', 'msteams', 'explanation', 'situation', 'unnecessary', 'explain', 'resolvedal', 'cole', 'great', 'nice', 'within', 'minutes', 'call.alex', 'important', 'impacting', 'contractors', 'ability', 'access', 'applications', 'files.actually', 'issue.solved', 'issuefound', 'able', 'finish', 'processing', 'worksupport', 'had', 'video', 'conversion', 'addressed', 'timely.1.', 'completely', '2.', 'knew', '3.', 'kind/pleasant', 'experience', 'thanks', 'christopher', 'henry', 'way', 'go', 'look', 'causing', 'first', 'place', 'try', 'phonetook', 'really', 'pretty', 'much', 'no', 'assistance', 'me', 'felt', 'good', 'put', 'watch', 'get', 'taken', 'of.info']\n",
      "{}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "We need at least 1 word to plot a word cloud, got 0.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-390-0fa1cac45184>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgenerateClusterClouds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabelledPos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-386-06e9a86986ae>\u001b[0m in \u001b[0;36mgenerateClusterClouds\u001b[1;34m(comments, numClusters)\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrequencies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[0mcustomCloud\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_from_frequencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrequencies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcustomCloud\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"bilinear\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_frequencies\u001b[1;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[0mfrequencies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrequencies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrequencies\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 390\u001b[1;33m             raise ValueError(\"We need at least 1 word to plot a word cloud, \"\n\u001b[0m\u001b[0;32m    391\u001b[0m                              \"got %d.\" % len(frequencies))\n\u001b[0;32m    392\u001b[0m         \u001b[0mfrequencies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfrequencies\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_words\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: We need at least 1 word to plot a word cloud, got 0."
     ]
    }
   ],
   "source": [
    "generateClusterClouds(labelledPos, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''To Do:\n",
    "cluster\n",
    "fix punctuation thing\n",
    "put as many things into functions as possible\n",
    "tweak model and training (different vectorizer, kernel, implementing stemming, stopwords)\n",
    "make interface'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
